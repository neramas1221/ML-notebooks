# -*- coding: utf-8 -*-
"""music_generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1drWnB61avZblbdNHU07XBmYzJEwtP2af
"""

from google.colab import drive
drive.mount('/content/gdrive')

from music21 import converter,instrument,note,chord,stream
import glob
import numpy as np
import pickle
from keras.utils import np_utils
from dask import delayed
from tqdm import tqdm
from keras.models import load_model

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

# !ls "/content/gdrive/My Drive/8-bit"

notes = [] # create array of notes

for midi in tqdm(glob.glob("/content/gdrive/My Drive/pokemon/*.mid")):
	conv  = converter.parse(midi)
	ntp   = None # Notes to pass

	parts = instrument.partitionByInstrument(conv)

	if parts: # file has instrument parts
		ntp = parts.parts[0].recurse()
	else: # file has notes in a flat structure
	    ntp = conv.flat.notes
	for element in ntp:
		if isinstance(element,note.Note):
			notes.append(str(element.pitch))
		elif isinstance(element,chord.Chord):
			notes.append('.'.join(str(n) for n in element.normalOrder))

print("done reading files")
n_vocab = len(set(notes))

# how long each sequance of notes will be
sequence_lenghth = 20

# get all pitches
pitch_n = sorted(set(item for item in notes))

# create map function from string to int
note_to_map = dict((note,number)for number,note in enumerate(pitch_n))

network_in  = []
network_out = []
# create input and output data
for i in tqdm(range (0, len(notes) - sequence_lenghth,1)):
  sequence_in = notes[i:i +sequence_lenghth]
  sequence_out = notes[i + sequence_lenghth]
  network_in.append([note_to_map[char] for char in sequence_in])
  network_out.append(note_to_map[sequence_out])


n_patterns = len(network_in)

# reshape input for network input layer
network_in = np.reshape(network_in,(n_patterns,sequence_lenghth,1))

network_in = network_in/float(n_vocab)

network_output = np_utils.to_categorical(network_out)

pickle.dump(network_output,open("/content/gdrive/My Drive/midi_converted/network_output.p","wb"),protocol=4)
pickle.dump(network_in,open("/content/gdrive/My Drive/midi_converted/network_input.p","wb"),protocol=4)

pickle_in = open("/content/gdrive/My Drive/midi_converted/network_output.p","rb")
network_out = pickle.load(pickle_in)

pickle_in = open("/content/gdrive/My Drive/midi_converted/network_input.p","rb")
network_in = pickle.load(pickle_in)

# Commented out IPython magic to ensure Python compatibility.
import os
import pprint
# %tensorflow_version 1.x
import tensorflow as tf

if 'COLAB_TPU_ADDR' not in os.environ:
  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')
else:
  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
  print ('TPU address is', tpu_address)

  with tf.Session(tpu_address) as session:
    devices = session.list_devices()
    
  print('TPU devices:')
  pprint.pprint(devices)

from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint
from keras.models import load_model
import os

input_size = (network_in.shape[1],network_in.shape[2])

model = Sequential()
model.add(LSTM(256,input_shape=input_size, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(256))
model.add(Dense(256))
model.add(Dropout(0.3))
model.add(Dense(n_vocab))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
# if os.path.exists("/content/gdrive/My Drive/midi_converted/weights-improvement-24-1.7539-bigger"):
print("loading model")
model = load_model("/content/gdrive/My Drive/midi_converted/final_model.h5")

filepath = "/content/gdrive/My Drive/midi_converted/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5"  

checkpoint = ModelCheckpoint(
    filepath, monitor='loss', 
    verbose=0,        
    save_best_only=True,        
    mode='min'
)    
callbacks_list = [checkpoint]

model.fit(network_in, network_output, epochs=50, batch_size=5120, callbacks=callbacks_list)

model.save("/content/gdrive/My Drive/midi_converted/final_model.h5")

start = np.random.randint(0, len(network_in)-1)
int_to_note = dict((number, note) for number, note in enumerate(pitch_n))

pattern = list(network_in[start])
prediction_output = []# generate 500 notes
for note_index in tqdm(range(500)):
    prediction_input = np.reshape(pattern, (1, len(pattern), 1))
    prediction_input = prediction_input / float(n_vocab)   
    prediction = model.predict(prediction_input, verbose=0)   
    index = np.argmax(prediction)
    result = int_to_note[index]
    prediction_output.append(result)    
    pattern.append(index)
    pattern = pattern[1:len(pattern)]

offset = 0
output_notes = []

# create note and chord objects based on the values generated by the model

for pattern in tqdm(prediction_output):
    # pattern is a chord
    if ('.' in pattern) or pattern.isdigit():
        notes_in_chord = pattern.split('.')
        notes = []
        for current_note in notes_in_chord:
            new_note = note.Note(int(current_note))
            new_note.storedInstrument = instrument.Piano()
            notes.append(new_note)
        new_chord = chord.Chord(notes)
        new_chord.offset = offset
        output_notes.append(new_chord)
    # pattern is a note
    else:
        new_note = note.Note(pattern)
        new_note.offset = offset
        new_note.storedInstrument = instrument.Piano()
        output_notes.append(new_note)    # increase offset each iteration so that notes do not stack
    offset += 0.5
midi_stream = stream.Stream(output_notes)

midi_stream.write('midi', fp='/content/gdrive/My Drive/midi_converted/test_output.mid')